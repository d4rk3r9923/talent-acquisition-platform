{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"3678ad53936b423c945e98a4042a54f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9fc0bdb6fc44314a30022fedd40736d","IPY_MODEL_58aed0adf72240968b9ecbb054aa4e07","IPY_MODEL_49ccde7e04ba416e819c813a66cb4fed"],"layout":"IPY_MODEL_38db07b7dea248a19e10ecb5bf5449f0"}},"b9fc0bdb6fc44314a30022fedd40736d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61d5724f9d804a3f833bee5b145b93c1","placeholder":"​","style":"IPY_MODEL_39578213db5d4b3ba263d7af8015a077","value":"Map (num_proc=2): 100%"}},"58aed0adf72240968b9ecbb054aa4e07":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_153d695617d24716b2355f310573904b","max":3703,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f63336739bc4611ac3253bf2ed25af5","value":3703}},"49ccde7e04ba416e819c813a66cb4fed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d00300fae1442379e9308ac8411e53a","placeholder":"​","style":"IPY_MODEL_1ae1137c21264f51a9808c25434dc7b2","value":" 3703/3703 [00:10&lt;00:00, 526.03 examples/s]"}},"38db07b7dea248a19e10ecb5bf5449f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61d5724f9d804a3f833bee5b145b93c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39578213db5d4b3ba263d7af8015a077":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"153d695617d24716b2355f310573904b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f63336739bc4611ac3253bf2ed25af5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d00300fae1442379e9308ac8411e53a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ae1137c21264f51a9808c25434dc7b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b459ba5db904da5aff0b12c7d366f27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45ccaa1cc2fe48b0894a4109e6046665","IPY_MODEL_5cab8ab59ac74e45b8a4e4e48309bfaf","IPY_MODEL_7aef3c768c5341ba97173b8b701edf95"],"layout":"IPY_MODEL_e4e0bc45241a48fe9b0f7534bb0a63c0"}},"45ccaa1cc2fe48b0894a4109e6046665":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34c89c14235047738bf44e8a1313519a","placeholder":"​","style":"IPY_MODEL_6dd573473c9e48b7b104eb3fb8cc6741","value":"Map: 100%"}},"5cab8ab59ac74e45b8a4e4e48309bfaf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8583d542f0194016942c982f2076108e","max":3703,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9fd9c3e8e26f427caf457cd959f0fda1","value":3703}},"7aef3c768c5341ba97173b8b701edf95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_747b489925054587a467aee7393ec4de","placeholder":"​","style":"IPY_MODEL_21e599a03c404bcc9e1a03a1532eca39","value":" 3703/3703 [00:03&lt;00:00, 1132.87 examples/s]"}},"e4e0bc45241a48fe9b0f7534bb0a63c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34c89c14235047738bf44e8a1313519a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dd573473c9e48b7b104eb3fb8cc6741":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8583d542f0194016942c982f2076108e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fd9c3e8e26f427caf457cd959f0fda1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"747b489925054587a467aee7393ec4de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21e599a03c404bcc9e1a03a1532eca39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9991875,"sourceType":"datasetVersion","datasetId":6050693}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n!pip install unsloth==2024.11.7","metadata":{"_uuid":"e7b755e0-3342-49fa-bbca-5ee0cfcf7e70","_cell_guid":"6bcfbd25-2de3-4c28-b959-e66d12021a32","collapsed":false,"id":"2eSvM9zX_2d3","jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:05:35.690650Z","iopub.execute_input":"2024-11-23T14:05:35.690938Z","iopub.status.idle":"2024-11-23T14:08:49.298986Z","shell.execute_reply.started":"2024-11-23T14:05:35.690911Z","shell.execute_reply":"2024-11-23T14:08:49.297676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nimport torch\nfrom kaggle_secrets import UserSecretsClient\nimport os\n\nwarnings.filterwarnings(\"ignore\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Your device:\", device)\nuser_secrets = UserSecretsClient()\nos.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ[\"WANDB_PROJECT\"]=\"QueryExtraction\"","metadata":{"_uuid":"6647180a-392e-47cd-b55d-03495f99ec76","_cell_guid":"a9a9bbdb-cfd5-4e82-84fc-0c7c7b6f274c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:08:49.301014Z","iopub.execute_input":"2024-11-23T14:08:49.301313Z","iopub.status.idle":"2024-11-23T14:08:51.294177Z","shell.execute_reply.started":"2024-11-23T14:08:49.301285Z","shell.execute_reply":"2024-11-23T14:08:51.293227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import FastLanguageModel\n\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"_uuid":"d1d106f0-d99d-4633-945f-584b9384197b","_cell_guid":"8290bb6d-7fdf-48e6-9af1-f1b894c9247f","collapsed":false,"id":"QmUBVEnvCDJv","outputId":"056d28cc-3f86-4f08-f70e-b4058bf8e3b8","jupyter":{"outputs_hidden":false},"_kg_hide-output":true,"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:08:51.295247Z","iopub.execute_input":"2024-11-23T14:08:51.295641Z","iopub.status.idle":"2024-11-23T14:09:38.955133Z","shell.execute_reply.started":"2024-11-23T14:08:51.295612Z","shell.execute_reply":"2024-11-23T14:09:38.954377Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We now add LoRA adapters so we only need to update 1 to 10% of all parameters!","metadata":{"_uuid":"0c45317a-66aa-43f0-a1e3-ea25ccadc251","_cell_guid":"6a3c4363-0fa8-40b0-a701-103821ec9e01","id":"SXd9bTZd1aaL","trusted":true}},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"_uuid":"e0541013-f227-4093-8e31-47ca9ec4541f","_cell_guid":"c1a001aa-7896-43b8-a3fb-b078844e35a8","collapsed":false,"id":"6bZsfBuZDeCL","outputId":"10350592-b856-4a6d-f587-8353977f8522","jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:09:38.957132Z","iopub.execute_input":"2024-11-23T14:09:38.957443Z","iopub.status.idle":"2024-11-23T14:09:44.773198Z","shell.execute_reply.started":"2024-11-23T14:09:38.957410Z","shell.execute_reply":"2024-11-23T14:09:44.772203Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Data Prep\nWe now use the `Llama-3.1` format for conversation style finetunes. conversations like below:\n\n```\n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\nHello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nHey there! How are you?<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nI'm great thanks!<|eot_id|>\n```","metadata":{"_uuid":"ad908349-c6c3-49cd-9c44-1bb18b9a1436","_cell_guid":"6a9f2228-fa41-4514-8e1b-bad8946ab80a","id":"vITh0KVJ10qX","trusted":true}},{"cell_type":"code","source":"from unsloth.chat_templates import get_chat_template\n\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"llama-3.1\",\n)\n\ndef formatting_prompts_func(examples):\n    convos = examples[\"conversations\"]\n    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n    return { \"text\" : texts, }\n\nfrom datasets import load_dataset\n\ntrainset = load_dataset('json', data_files='/kaggle/input/query-extraction/training_set.jsonl', split=\"train\")\nvalidationset = load_dataset('json', data_files='/kaggle/input/query-extraction/validation_set.jsonl', split=\"train\")","metadata":{"_uuid":"9d57be5b-cc54-4c9f-9881-bb91f36cc0ff","_cell_guid":"49edd11f-0e74-41e2-9d88-ce6706aebc48","collapsed":false,"id":"LjY75GoYUCB8","jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:09:44.774193Z","iopub.execute_input":"2024-11-23T14:09:44.774505Z","iopub.status.idle":"2024-11-23T14:09:45.286972Z","shell.execute_reply.started":"2024-11-23T14:09:44.774476Z","shell.execute_reply":"2024-11-23T14:09:45.286116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainset = trainset.map(formatting_prompts_func, batched = True,)\nvalidationset = validationset.map(formatting_prompts_func, batched = True,)","metadata":{"_uuid":"c67c3150-8a14-43fa-bf1f-db8613e6bb0c","_cell_guid":"0bea3436-aba4-4a2c-aaf5-ed618115cd05","collapsed":false,"id":"oPXzJZzHEgXe","jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:09:45.288262Z","iopub.execute_input":"2024-11-23T14:09:45.288649Z","iopub.status.idle":"2024-11-23T14:09:45.758965Z","shell.execute_reply.started":"2024-11-23T14:09:45.288605Z","shell.execute_reply":"2024-11-23T14:09:45.758160Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We look at how the conversations are structured for item 5:","metadata":{"_uuid":"1c5269ce-5112-4eb9-986e-0819e9ab223b","_cell_guid":"188c0eed-9eb4-4efb-9d56-fb4e49811c53","id":"ndDUB23CGAC5","trusted":true}},{"cell_type":"code","source":"print(trainset[5][\"conversations\"])","metadata":{"_uuid":"ef02ef93-9737-4182-9cbc-70d1f7067d84","_cell_guid":"ce90edd2-648c-45a2-b194-3619eba2ed20","collapsed":false,"id":"gGFzmplrEy9I","outputId":"d087609d-c747-4626-a2f8-9aadf3c52c43","jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:09:45.760053Z","iopub.execute_input":"2024-11-23T14:09:45.760321Z","iopub.status.idle":"2024-11-23T14:09:45.764836Z","shell.execute_reply.started":"2024-11-23T14:09:45.760293Z","shell.execute_reply":"2024-11-23T14:09:45.763896Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"And we see how the chat template transformed these conversations.","metadata":{"_uuid":"6f86f693-937a-4f82-ad59-c83bcee9bcb1","_cell_guid":"eab9dc2a-2486-477b-b29e-7ee1019b9ffc","id":"GfzTdMtvGE6w","trusted":true}},{"cell_type":"code","source":"print(trainset[5][\"text\"])","metadata":{"_uuid":"ab25403f-22de-47c9-8fc4-24d9e378b90a","_cell_guid":"79ed0d27-2bc9-48a7-b76a-eb18b2b5e5f5","collapsed":false,"id":"vhXv0xFMGNKE","outputId":"666cc2f2-441d-43bb-a32d-84943b5df501","jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:09:45.765850Z","iopub.execute_input":"2024-11-23T14:09:45.766106Z","iopub.status.idle":"2024-11-23T14:09:45.780952Z","shell.execute_reply.started":"2024-11-23T14:09:45.766081Z","shell.execute_reply":"2024-11-23T14:09:45.780185Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a name=\"Train\"></a>\n### Train the model\nNow let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!","metadata":{"_uuid":"eb147401-2d16-414d-ac4a-20e1a42db291","_cell_guid":"c2fb74d0-3ecd-4575-a588-8d1198b72f8d","id":"idAEIeSQ3xdS","trusted":true}},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments, DataCollatorForSeq2Seq\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = trainset,\n    eval_dataset = validationset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 8,\n        per_device_eval_batch_size = 8,\n        gradient_accumulation_steps = 4,\n        eval_accumulation_steps = 4,\n        warmup_steps = 6,\n        num_train_epochs = 4,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 5,\n        eval_steps = 5,\n        eval_strategy=\"steps\",\n        logging_strategy=\"steps\",\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"cosine\",\n        seed = 3407,\n        output_dir = \"Llama3.1-8B-Instruct\",\n        report_to = \"wandb\",\n        logging_dir=\"./logs\",\n        save_strategy=\"steps\",\n        save_steps=5,\n        save_total_limit=1,\n        metric_for_best_model=\"eval_loss\",\n        greater_is_better=False,\n    ),\n)","metadata":{"_uuid":"a9c1c865-9ab9-4f2c-9dbb-e4104898dfab","_cell_guid":"ff565620-3b94-49d0-bdc7-0a4d094ef5c8","collapsed":false,"id":"95_Nn-89DhsL","outputId":"5c477d47-dfd6-4659-c686-10a5df3e32a5","jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:09:45.781866Z","iopub.execute_input":"2024-11-23T14:09:45.782124Z","iopub.status.idle":"2024-11-23T14:09:49.973534Z","shell.execute_reply.started":"2024-11-23T14:09:45.782099Z","shell.execute_reply":"2024-11-23T14:09:49.972608Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We also use Unsloth's train_on_responses_only method to only train on the assistant outputs and ignore the loss on the user's inputs.","metadata":{}},{"cell_type":"code","source":"from unsloth.chat_templates import train_on_responses_only\ntrainer = train_on_responses_only(\n    trainer,\n    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:09:49.978746Z","iopub.execute_input":"2024-11-23T14:09:49.979120Z","iopub.status.idle":"2024-11-23T14:09:50.162377Z","shell.execute_reply.started":"2024-11-23T14:09:49.979085Z","shell.execute_reply":"2024-11-23T14:09:50.161656Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We verify masking is actually done:","metadata":{}},{"cell_type":"code","source":"print(tokenizer.decode(trainer.train_dataset[5][\"input_ids\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:09:50.163678Z","iopub.execute_input":"2024-11-23T14:09:50.164029Z","iopub.status.idle":"2024-11-23T14:09:50.173352Z","shell.execute_reply.started":"2024-11-23T14:09:50.163988Z","shell.execute_reply":"2024-11-23T14:09:50.172451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\ntokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:09:50.174503Z","iopub.execute_input":"2024-11-23T14:09:50.174756Z","iopub.status.idle":"2024-11-23T14:09:50.193199Z","shell.execute_reply.started":"2024-11-23T14:09:50.174732Z","shell.execute_reply":"2024-11-23T14:09:50.192441Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can see the System and Instruction prompts are successfully masked!","metadata":{"_uuid":"fe0ba9d7-a031-450a-beeb-1a68cde5cdee","_cell_guid":"15c54306-e8fd-4a30-90e9-484fc704475a","id":"3enWUM0jV-jV","trusted":true}},{"cell_type":"code","source":"#@title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"_uuid":"13f478ae-98ec-4179-afff-7f17f22bc622","_cell_guid":"d1356e04-f3cc-4a07-9680-2cac2263a5d6","collapsed":false,"cellView":"form","id":"2ejIt2xSNKKp","outputId":"f4538e04-3652-4848-8788-26b93532e3b2","jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:09:50.194234Z","iopub.execute_input":"2024-11-23T14:09:50.194492Z","iopub.status.idle":"2024-11-23T14:09:50.205211Z","shell.execute_reply.started":"2024-11-23T14:09:50.194468Z","shell.execute_reply":"2024-11-23T14:09:50.204465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"_uuid":"5f187a26-43ba-43d9-879c-b61d10572ac2","_cell_guid":"c208665c-c01b-4f86-95a2-a53a77b06145","collapsed":false,"id":"yqxqAZ7KJ4oL","outputId":"9067570a-ef20-423d-c235-0028fe31903f","jupyter":{"outputs_hidden":false},"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:09:50.206134Z","iopub.execute_input":"2024-11-23T14:09:50.206465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#@title Show final memory and time stats\nused_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory         /max_memory*100, 3)\nlora_percentage = round(used_memory_for_lora/max_memory*100, 3)\nprint(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\nprint(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")","metadata":{"_uuid":"3346a94b-df83-4566-ae96-d41271283d7e","_cell_guid":"a05f7daa-ccd3-417b-b667-e66455e2b6fc","collapsed":false,"cellView":"form","id":"pCqnaKmlO1U9","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"lora_model\") # Local saving\ntokenizer.save_pretrained(\"lora_model\")","metadata":{"_uuid":"a6943875-265b-4353-b389-e3f09dc4ff7b","_cell_guid":"7d04d3c3-7cc3-4c46-a0fd-88d09363c263","collapsed":false,"id":"FqfebeAdT073","jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r model.zip /kaggle/working","metadata":{"_uuid":"3e9ba339-037f-4f9b-9660-49bb06b0db09","_cell_guid":"a22a285e-fdca-4315-bd28-97927a212610","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'model.zip')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}